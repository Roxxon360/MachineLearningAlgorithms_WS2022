{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Ilyes Justin m12001643 <br>\n",
    "Seidl Stefan m11804717 <br>\n",
    "Wagermaier Daniel m01605389"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Definition of input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#These filename need to be defined:\n",
    "digits_train_filename = 'data/traindigits.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Calc1: Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# --- Execution mandatory --- #\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "digits_train = np.loadtxt(digits_train_filename, delimiter=',', skiprows=1)\n",
    "\n",
    "# import Data\n",
    "data = pd.read_csv('digits_train_filename.csv').astype('uint8')\n",
    "\n",
    "X = data.iloc[:,:-1].values.reshape(len(data), 28, 28, 1)\n",
    "X = np.array(X)\n",
    "X = X / 255.0 # normalize with max value\n",
    "\n",
    "y = data.iloc[:,-1].values\n",
    "labels = to_categorical(y, num_classes = 10)\n",
    "labels = np.array(labels)\n",
    "\n",
    "X = data[:, :-1]\n",
    "y = data[:, -1]\n",
    "\n",
    "test_size = 0.1\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=test_size, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Explore"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network Classification: Hyperparameter Search"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define method for hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "\n",
    "def build_model(hp):\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "    previous_layer_filters = hp.Int('filter0', min_value=64, max_value=128, step=32)\n",
    "    model.add(Conv2D(previous_layer_filters, \n",
    "                    kernel_size=5, \n",
    "                    activation = 'relu', \n",
    "                    input_shape = (28, 28, 1)))\n",
    "    model.add(MaxPooling2D(pool_size=3))\n",
    "\n",
    "    layers = hp.Int('n_layers', min_value=2, max_value=3, step=1)\n",
    "\n",
    "    for i in range(layers):\n",
    "            previous_layer_filters = hp.Int(f'filter{i+1}', min_value = previous_layer_filters, max_value=256, step=32)\n",
    "            model.add(Conv2D(previous_layer_filters, \n",
    "                            kernel_size=hp.Int(f'kernel{i+1}', min_value=3, max_value=5, step=2), \n",
    "                            activation = 'relu'))\n",
    "            \n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(hp.Int('dense', min_value=128, max_value=256, step=64)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(hp.Float('dropout', min_value = 0.25, max_value = 0.5, step = 0.25)))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    hp_lr_adadelta = hp.Choice('learning_rate_adadelta', values=[1.5, 1.0, 0.5])\n",
    "    optimizer = tf.keras.optimizers.Adadelta(learning_rate=hp_lr_adadelta)\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer=optimizer, metrics =['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_tuner import RandomSearch, BayesianOptimization, Hyperband\n",
    "tuner_rs = RandomSearch(build_model, objective='val_accuracy', max_trials=50, overwrite = False, project_name='RandomSearch2', directory = 'ass3')\n",
    "tuner_rs.search(X_train, y_train, epochs=10, validation_data = (X_test, y_test))\n",
    "\n",
    "'''\n",
    "'values': {'filter0': 96, 'kernel0': 5, 'n_layers': 2, 'filter1': 96, 'kernel1': 5, 'dropout_1': False, 'dense': 192, 'dropout_2': True, 'learning_rate_adadelta': 1.0, \n",
    "'learning_rate_adam': 0.0001, 'optimizer': 'adadelta', 'filter2': 160, 'kernel2': 3, 'dropout2': 0.5, 'dropout1': 0.25}\n",
    "\n",
    "score: 0.9850000143051147\n",
    "'''\n",
    "\n",
    "tuner_bo = BayesianOptimization(build_model, objective='val_accuracy', max_trials=50, overwrite = False, project_name='BayesianOptimization2', directory = 'ass3')\n",
    "tuner_bo.search(X_train, y_train, epochs=10, validation_data = (X_test, y_test))\n",
    "\n",
    "'''\n",
    "'values': {'filter0': 64, 'kernel0': 5, 'n_layers': 1, 'filter1': 64, 'kernel1': 3, 'dropout_1': False, 'dense': 256, 'dropout_2': False, \n",
    "'learning_rate_adadelta': 1.0, 'learning_rate_adam': 0.0001, 'optimizer': 'adadelta', 'filter2': 256, 'kernel2': 5, 'dropout1': 0.5, 'dropout2': 0.25\n",
    "\n",
    "score: 0.9850000143051147\n",
    "'''\n",
    "\n",
    "tuner_hb = Hyperband(build_model, objective='val_accuracy', max_epochs=15, overwrite = False, project_name='Hyperband2', directory = 'ass3')\n",
    "tuner_hb.search(X_train, y_train, epochs=10, validation_data = (X_test, y_test))\n",
    "\n",
    "'''\n",
    "'values': {'filter0': 64, 'kernel0': 3, 'n_layers': 2, 'filter1': 256, 'kernel1': 5, 'dropout_1': True, 'dense': 128, 'dropout_2': False, \n",
    "'learning_rate_adadelta': 0.1, 'learning_rate_adam': 0.001, 'optimizer': 'adam', 'tuner/epochs': 12, 'tuner/initial_epoch': 4, \n",
    "'tuner/bracket': 2, 'tuner/round': 2, 'filter2': 256, 'kernel2': 3, 'dropout1': 0.25\n",
    "\n",
    "score: 0.9783333539962769\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Calc2: Convolutional Neural Network Classifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build CNN classifier with found hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Execution mandatory --- #\n",
    "from keras.models import Sequential\n",
    "from keras.layers import BatchNormalization\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#model.add(data_augmentation)\n",
    "model.add(Conv2D(64, kernel_size=3, activation = 'relu', input_shape = (28, 28, 1)))\n",
    "model.add(Conv2D(64, kernel_size=3, activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, kernel_size=3, activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "opt = tf.keras.optimizers.Adadelta(learning_rate=0.6)\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer=opt, metrics =['accuracy'])\n",
    "model.fit(X_train, y_train, validation_split = 0.1, epochs = 10, batch_size = 32)\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimation of accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Final classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "digits_CNN = model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".MachineLearningAlg_venv_3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "41c5dfa9ea940b29d91c14fce0803ccaa1b9e9d4431f973e93874b0c9807f393"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
