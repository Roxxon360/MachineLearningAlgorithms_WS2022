{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c4f40d5",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "\n",
    "__*m12001643 Ilyes Justin <br>\n",
    "m11804717 Seidl Stefan <br>\n",
    "m01605389 Wagemaier Daniel*__ <br>\n",
    "\n",
    "## 1) Import Librarys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aca18d0",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "import sklearn.model_selection as skms\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39098c6d",
   "metadata": {},
   "source": [
    "## 2) Import data and create test, training and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e32f988",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'alldigits.csv'\n",
    "df = pd.read_csv(file_name)\n",
    "data = df.to_numpy()\n",
    "\n",
    "X = data[:, :-1]\n",
    "y = data[:, -1]\n",
    "\n",
    "test_size = 0.1\n",
    "validation_size = 0.2\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=0)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=validation_size/(1-test_size), random_state=0)\n",
    "\n",
    "total_points_testSet = len(y_test)\n",
    "total_points_valSet = len(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2b271e",
   "metadata": {},
   "source": [
    "## 3) Plotting the Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23615629",
   "metadata": {},
   "outputs": [],
   "source": [
    "pictures = []\n",
    "picture_size = 28\n",
    "for row in data:\n",
    "    single_picture_matrix = []\n",
    "    for i in range(picture_size):\n",
    "        inner_list = []\n",
    "        for j in range(picture_size):\n",
    "            inner_list.append(int(row[j * picture_size + i]))\n",
    "        single_picture_matrix.append(inner_list)\n",
    "    pictures.append(single_picture_matrix)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [10, 5] #change inline figure size [width, higth]\n",
    "n = 200    \n",
    "plt.imshow(pictures[n], cmap='Greys_r', vmin=0, vmax=255)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469be9d6",
   "metadata": {},
   "source": [
    "# 4) Analyse the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf05840d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Points in Trainset: \" + str(len(y_train)))\n",
    "print(\"Points in Testset: \" + str(len(y_test)))\n",
    "print(\"Points in Validationset: \" + str(len(y_val)))\n",
    "print(\"Test/Train Ratio: \" + str(len(y_test)/len(y_train)))\n",
    "print(\"Validation/Train Ratio: \" + str(len(y_val)/len(y_train)))\n",
    "\n",
    "plt.figure(1)\n",
    "plt.align = \"mid\"\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(y_train,10,edgecolor=\"black\")\n",
    "plt.title(\"Train-Data\")\n",
    "plt.xlabel(\"Numbers\")\n",
    "plt.ylabel(\"Datapoints\")\n",
    "\n",
    "#plt.subplot(1, 2, 2)\n",
    "plt.hist(y_val,10,edgecolor=\"black\")\n",
    "plt.title(\"Validation-Data & Test-Data\")\n",
    "plt.xlabel(\"Numbers\")\n",
    "plt.ylabel(\"Datapoints\")\n",
    "\n",
    "plt.hist(y_test,10,edgecolor=\"black\")\n",
    "plt.title(\"Test-Data\")\n",
    "plt.ylabel(\"Datapoints\")\n",
    "plt.xlabel(\"Numbers\")\n",
    "\n",
    "plt.legend([\"Train-Data\", \"Validation-Data\", \"Test-Data\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7e32aa",
   "metadata": {},
   "source": [
    "# 5) Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79eeb4c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dtc = tree.DecisionTreeClassifier() # creates the decision tree classifier (default = \"gini\")\n",
    "dtc.fit(X_train, y_train) # trains the model\n",
    "predicted = dtc.predict(X_val) # classifies/predicts incoming test data\n",
    "\n",
    "dtc_correct_labeled = (y_val == predicted).sum()\n",
    "print(\"Correct labeled(Decision Tree): \" + str(dtc_correct_labeled) + \" from \" + \\\n",
    "      str(total_points_testSet) + \" (\" + str((dtc_correct_labeled/total_points_valSet)*100) +\"%)\")\n",
    "\n",
    "print(\n",
    "    f\"Classification report of DecisionTreeClassifier():\\n\"\n",
    "    f\"{classification_report(y_val, predicted, digits=3)}\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9555447b-6210-424f-92d0-c4482eba1a0a",
   "metadata": {
    "tags": []
   },
   "source": [
    "<span style=\"font-size:15px;\"> **Precision**: <span style=\"font-size:13px;\"> percentage of correct predictions <br />\n",
    "<span style=\"font-size:15px;\"> **Recall**: <span style=\"font-size:13px;\"> percentage of positive cases found <br />\n",
    "<span style=\"font-size:15px;\"> **F1 score**: <span style=\"font-size:13px;\"> measure of a test's accuracy (relies solely on precision and recall) <br />\n",
    "<span style=\"font-size:15px;\"> **Accuracy**: <span style=\"font-size:13px;\"> mean of F1 Score <br />\n",
    "<span style=\"font-size:15px;\"> **Macro Average**: <span style=\"font-size:13px;\"> unweighted mean for all labels <br />\n",
    "<span style=\"font-size:15px;\"> **Weighted Average**: <span style=\"font-size:13px;\"> weighted mean based off of support from each label <br />\n",
    "<br />\n",
    "<span style=\"font-size:15px;\"> $$ Precision = {True Positive \\over (True Positive + False Positive)} $$  <br />\n",
    "<span style=\"font-size:15px;\"> $$ Recall = {True Positive \\over (True Positive + False Negative)} $$  <br />\n",
    "<span style=\"font-size:15px;\"> $$ F1 score = {2*(Precision*Recall) \\over (Precision+Recall)} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b973face",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [20, 10] #change inline figure size [width, higth]\n",
    "tree.plot_tree(dtc)\n",
    "plt.show() # visualizes the decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca919500",
   "metadata": {},
   "source": [
    "# 6) Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145a0f2a",
   "metadata": {},
   "source": [
    "## 6.1) Gaussian \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d12decb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gNB = GaussianNB()\n",
    "y_pred_gauss = gNB.fit(X_train, y_train).predict(X_val)\n",
    "gauss_correct_labeled = (y_val == y_pred_gauss).sum()\n",
    "print(\"Correct labeled(Gauss): \" + str(gauss_correct_labeled) + \" from \" + \\\n",
    "      str(total_points_valSet) + \" (\" + str(round((gauss_correct_labeled/total_points_valSet)*100,2)) +\"%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7729dd",
   "metadata": {},
   "source": [
    "## 6.2) Multinominal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8561a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mNB = MultinomialNB()\n",
    "y_pred_multi = mNB.fit(X_train, y_train).predict(X_val)\n",
    "multi_correct_labeled = (y_val == y_pred_multi).sum()\n",
    "print(\"Correct labeled(Multinominal): \" + str(multi_correct_labeled) + \" from \" + \\\n",
    "      str(total_points_valSet) + \" (\" + str(round((multi_correct_labeled/total_points_valSet)*100,2)) +\"%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f83f0ef",
   "metadata": {},
   "source": [
    "## 6.3) Complement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7be85b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cNB = ComplementNB()\n",
    "y_pred_comp = cNB.fit(X_train, y_train).predict(X_val)\n",
    "comp_correct_labeled = (y_val == y_pred_comp).sum()\n",
    "print(\"Correct labeled(Complement): \" + str(comp_correct_labeled) + \" from \" + \\\n",
    "      str(total_points_valSet) + \" (\" + str(round((comp_correct_labeled/total_points_valSet)*100,2)) +\"%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a088cf4",
   "metadata": {},
   "source": [
    "## 6.4) Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1721c2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "bNB = BernoulliNB()\n",
    "y_pred_bNB = bNB.fit(X_train, y_train).predict(X_val)\n",
    "ber_correct_labeled = (y_val == y_pred_bNB).sum()\n",
    "print(\"Correct labeled(Bernoulli): \" + str(ber_correct_labeled) + \" from \" + \\\n",
    "      str(total_points_valSet) + \" (\" + str(round((ber_correct_labeled/total_points_valSet)*100,2)) +\"%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b413d3",
   "metadata": {},
   "source": [
    "## 6.5) Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3116c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "catNB = CategoricalNB(min_categories=256)\n",
    "y_pred_cat = catNB.fit(X_train, y_train).predict(X_val)\n",
    "cat_correct_labeled = (y_val == y_pred_cat).sum()\n",
    "print(\"Correct labeled(Categorical): \" + str(cat_correct_labeled) + \" from \" + \\\n",
    "      str(total_points_valSet) + \" (\" + str(round((cat_correct_labeled/total_points_valSet)*100, 2)) +\"%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b07ec2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 6.6) Summary\n",
    "\n",
    "*RNG_Seed = 0*\n",
    "\n",
    "|test_size|Gaussian|Multinominal|Complement|Bernoulli|Categorical|Decision Tree|\n",
    "|---|---|---|---|---|---|---|\n",
    "|0.1|57.33|82.83|70.17|84.17|67.17|81.33|\n",
    "|0.3|56.28|82.67|70.22|83.83|62.56|76.17|\n",
    "|0.5|55.7|82.17|70.63|82.63|57.3|73.07|\n",
    "|0.7|56.12|82.26|70.95|81.95|48.74|71.29|\n",
    "|0.9|58.94|81.7|70.48|81.0|30.48|62.78|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2286c99",
   "metadata": {},
   "source": [
    "## 7) Error estimation and comparison\n",
    "\n",
    "To calculate the upper error boundary a confidence of 95% percent was chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec411a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence = 0.95\n",
    "c_significance = stats.norm.ppf((1 + confidence) / 2)\n",
    "\n",
    "y_pred = catNB.predict(X_test)\n",
    "catNB_emp_error = (len(y_test) - (y_test == y_pred).sum()) / len(y_test)\n",
    "catNB_upper_error = catNB_emp_error + c_significance * np.sqrt(catNB_emp_error * (1 - catNB_emp_error) / len(y_test)) + c_significance / len(y_test)\n",
    "print(\"CategoricalNB upper error: \" + str(catNB_upper_error))\n",
    "\n",
    "y_pred = bNB.predict(X_test)\n",
    "bNB_emp_error = (len(y_test) - (y_test == y_pred).sum()) / len(y_test)\n",
    "bNB_upper_error = bNB_emp_error + c_significance * np.sqrt(bNB_emp_error * (1 - bNB_emp_error) / len(y_test)) + c_significance / len(y_test)\n",
    "print(\"BernoulliNB upper error: \" + str(bNB_upper_error))\n",
    "\n",
    "y_pred = cNB.predict(X_test)\n",
    "cNB_emp_error = (len(y_test) - (y_test == y_pred).sum()) / len(y_test)\n",
    "cNB_upper_error = cNB_emp_error + c_significance * np.sqrt(cNB_emp_error * (1 - cNB_emp_error) / len(y_test)) + c_significance / len(y_test)\n",
    "print(\"ComplementNB upper error: \" + str(cNB_upper_error))\n",
    "\n",
    "y_pred = mNB.predict(X_test)\n",
    "mNB_emp_error = (len(y_test) - (y_test == y_pred).sum()) / len(y_test)\n",
    "mNB_upper_error = mNB_emp_error + c_significance * np.sqrt(mNB_emp_error * (1 - mNB_emp_error) / len(y_test)) + c_significance / len(y_test)\n",
    "print(\"MultinomialNB upper error: \" + str(mNB_upper_error))\n",
    "\n",
    "y_pred = gNB.predict(X_test)\n",
    "gNB_emp_error = (len(y_test) - (y_test == y_pred).sum()) / len(y_test)\n",
    "gNB_upper_error = gNB_emp_error + c_significance * np.sqrt(gNB_emp_error * (1 - gNB_emp_error) / len(y_test)) + c_significance / len(y_test)\n",
    "print(\"GaussianNB upper error: \" + str(gNB_upper_error))\n",
    "\n",
    "y_pred = dtc.predict(X_test)\n",
    "dtc_emp_error = (len(y_test) - (y_test == y_pred).sum()) / len(y_test)\n",
    "dtc_upper_error = dtc_emp_error + c_significance * np.sqrt(dtc_emp_error * (1 - dtc_emp_error) / len(y_test)) + c_significance / len(y_test)\n",
    "print(\"DecisionTreeClassifier upper error: \" + str(dtc_upper_error))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "4f09fca1dd3ffa6e83900143bd9a94cd954ee991162dd6798ff9944fa3d49a73"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
