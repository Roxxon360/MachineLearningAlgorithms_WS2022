{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c4f40d5",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "\n",
    "__*m12001643 Ilyes Justin <br>\n",
    "m11804717 Seidl Stefan <br>\n",
    "m01605389 Wagermaier Daniel*__ <br>\n",
    "\n",
    "## 1) Import Librarys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aca18d0",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "import sklearn.model_selection as skms\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39098c6d",
   "metadata": {},
   "source": [
    "## 2) Import data and create test, training and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e32f988",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = '../data/alldigits.csv'\n",
    "df = pd.read_csv(file_name)\n",
    "data = df.to_numpy()\n",
    "\n",
    "X = data[:, :-1]\n",
    "y = data[:, -1]\n",
    "\n",
    "test_size = 0.1\n",
    "validation_size = 0.2\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=0)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=validation_size/(1-test_size), random_state=0)\n",
    "\n",
    "total_points_testSet = len(y_test)\n",
    "total_points_valSet = len(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2b271e",
   "metadata": {},
   "source": [
    "## 3) Plotting the Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23615629",
   "metadata": {},
   "outputs": [],
   "source": [
    "pictures = []\n",
    "picture_size = 28\n",
    "for row in data:\n",
    "    single_picture_matrix = []\n",
    "    for i in range(picture_size):\n",
    "        inner_list = []\n",
    "        for j in range(picture_size):\n",
    "            inner_list.append(int(row[j * picture_size + i]))\n",
    "        single_picture_matrix.append(inner_list)\n",
    "    pictures.append(single_picture_matrix)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [10, 5] #change inline figure size [width, higth]\n",
    "n = 200    \n",
    "plt.imshow(pictures[n], cmap='Greys_r', vmin=0, vmax=255)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469be9d6",
   "metadata": {},
   "source": [
    "# 4) Analyse the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf05840d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Points in Trainset: \" + str(len(y_train)))\n",
    "print(\"Points in Testset: \" + str(len(y_test)))\n",
    "print(\"Points in Validationset: \" + str(len(y_val)))\n",
    "print(\"Test/Train Ratio: \" + str(len(y_test)/len(y_train)))\n",
    "print(\"Validation/Train Ratio: \" + str(len(y_val)/len(y_train)))\n",
    "\n",
    "plt.figure(1)\n",
    "plt.align = \"mid\"\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "nr_bins = len(set(y_train))\n",
    "plt.hist(y_train,edgecolor=\"black\",bins=nr_bins)\n",
    "plt.title(\"Train-Data\")\n",
    "plt.xlabel(\"Numbers\")\n",
    "plt.ylabel(\"Datapoints\")\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.hist(y_val,nr_bins,edgecolor=\"black\")\n",
    "plt.title(\"Validation-Data\")\n",
    "plt.xlabel(\"Numbers\")\n",
    "plt.ylabel(\"Datapoints\")\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.hist(y_test,nr_bins,edgecolor=\"black\")\n",
    "plt.title(\"Test-Data\")\n",
    "plt.ylabel(\"Datapoints\")\n",
    "plt.xlabel(\"Numbers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7e32aa",
   "metadata": {},
   "source": [
    "# 5) Decision Tree\n",
    "\n",
    "Prior to implementing the Decision Tree Classifier, we went through the sklearn documentation and ultimately decided to use the standard implementation with \"Gini Index\" as the default criteria. \n",
    "\n",
    "The accuracy of the classifiers was calculated according to the following formula:\n",
    "$$ Accuracy = \\frac{Number Correct Labeled Points}{Number All PointsValidation Set} $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79eeb4c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dtc = tree.DecisionTreeClassifier() # creates the decision tree classifier (default = \"gini\")\n",
    "dtc.fit(X_train, y_train) # trains the model\n",
    "predicted = dtc.predict(X_val) # classifies/predicts incoming test data\n",
    "\n",
    "dtc_correct_labeled = (y_val == predicted).sum()\n",
    "print(\"Correct labeled(Decision Tree): \" + str(dtc_correct_labeled) + \" from \" + \\\n",
    "      str(total_points_valSet) + \" (Accuracy: \" + str(round((dtc_correct_labeled/total_points_valSet)*100,2)) +\"%)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b973face",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [20, 10] #change inline figure size [width, higth]\n",
    "tree.plot_tree(dtc)\n",
    "plt.show() # visualizes the decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca919500",
   "metadata": {},
   "source": [
    "# 6) Naive Bayes\n",
    "\n",
    "After reviewing the documentation of the sklearn kit, we went on to implement the multiple Naive Bayes Classifiers into our code. The following methods were used: GaussianNB(), MultinomialNB(), ComplementNB(), BernoulliNB() and CategoricalNB(). For each of the classifiers, the default parameters were used in the implementations. \n",
    "\n",
    "The accuracy of the classifiers was calculated according to the following formula:\n",
    "$$ Accuracy = \\frac{Number Correct Labeled Points}{Number All PointsValidation Set} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145a0f2a",
   "metadata": {},
   "source": [
    "## 6.1) Gaussian \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d12decb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gNB = GaussianNB()\n",
    "y_pred_gauss = gNB.fit(X_train, y_train).predict(X_val)\n",
    "gauss_correct_labeled = (y_val == y_pred_gauss).sum()\n",
    "print(\"Correct labeled(Gauss): \" + str(gauss_correct_labeled) + \" from \" + \\\n",
    "      str(total_points_valSet) + \" (Accuracy: \" + str(round((gauss_correct_labeled/total_points_valSet)*100,2)) +\"%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7729dd",
   "metadata": {},
   "source": [
    "## 6.2) Multinominal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8561a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mNB = MultinomialNB()\n",
    "y_pred_multi = mNB.fit(X_train, y_train).predict(X_val)\n",
    "multi_correct_labeled = (y_val == y_pred_multi).sum()\n",
    "print(\"Correct labeled(Multinominal): \" + str(multi_correct_labeled) + \" from \" + \\\n",
    "      str(total_points_valSet) + \" (Accuracy: \" + str(round((multi_correct_labeled/total_points_valSet)*100,2)) +\"%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f83f0ef",
   "metadata": {},
   "source": [
    "## 6.3) Complement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7be85b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cNB = ComplementNB()\n",
    "y_pred_comp = cNB.fit(X_train, y_train).predict(X_val)\n",
    "comp_correct_labeled = (y_val == y_pred_comp).sum()\n",
    "print(\"Correct labeled(Complement): \" + str(comp_correct_labeled) + \" from \" + \\\n",
    "      str(total_points_valSet) + \" (Accuracy: \" + str(round((comp_correct_labeled/total_points_valSet)*100,2)) +\"%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a088cf4",
   "metadata": {},
   "source": [
    "## 6.4) Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1721c2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "bNB = BernoulliNB()\n",
    "y_pred_bNB = bNB.fit(X_train, y_train).predict(X_val)\n",
    "ber_correct_labeled = (y_val == y_pred_bNB).sum()\n",
    "print(\"Correct labeled(Bernoulli): \" + str(ber_correct_labeled) + \" from \" + \\\n",
    "      str(total_points_valSet) + \" (Accuracy: \" + str(round((ber_correct_labeled/total_points_valSet)*100,2)) +\"%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b413d3",
   "metadata": {},
   "source": [
    "## 6.5) Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3116c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "catNB = CategoricalNB(min_categories=256)\n",
    "y_pred_cat = catNB.fit(X_train, y_train).predict(X_val)\n",
    "cat_correct_labeled = (y_val == y_pred_cat).sum()\n",
    "print(\"Correct labeled(Categorical): \" + str(cat_correct_labeled) + \" from \" + \\\n",
    "      str(total_points_valSet) + \" (Accuracy: \" + str(round((cat_correct_labeled/total_points_valSet)*100, 2)) +\"%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2286c99",
   "metadata": {},
   "source": [
    "## 7) Error estimation and comparison\n",
    "\n",
    "To calculate the upper error boundary a confidence of 95% was chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec411a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence = 0.95\n",
    "c_significance = stats.norm.ppf((1 + confidence) / 2) # formula for two sided interval. Not necessary for one sided interval!\n",
    "\n",
    "y_pred = catNB.predict(X_test)\n",
    "catNB_emp_error = (len(y_test) - (y_test == y_pred).sum()) / len(y_test)\n",
    "catNB_upper_error = catNB_emp_error + c_significance * np.sqrt(catNB_emp_error * (1 - catNB_emp_error) / len(y_test)) + c_significance / len(y_test)\n",
    "print(\"CategoricalNB upper error: \" + str(round(catNB_upper_error * 100, 2)) + \"%\")\n",
    "\n",
    "y_pred = bNB.predict(X_test)\n",
    "bNB_emp_error = (len(y_test) - (y_test == y_pred).sum()) / len(y_test)\n",
    "bNB_upper_error = bNB_emp_error + c_significance * np.sqrt(bNB_emp_error * (1 - bNB_emp_error) / len(y_test)) + c_significance / len(y_test)\n",
    "print(\"BernoulliNB upper error: \" + str(round(bNB_upper_error * 100, 2)) + \"%\")\n",
    "\n",
    "y_pred = cNB.predict(X_test)\n",
    "cNB_emp_error = (len(y_test) - (y_test == y_pred).sum()) / len(y_test)\n",
    "cNB_upper_error = cNB_emp_error + c_significance * np.sqrt(cNB_emp_error * (1 - cNB_emp_error) / len(y_test)) + c_significance / len(y_test)\n",
    "print(\"ComplementNB upper error: \" + str(round(cNB_upper_error * 100, 2)) + \"%\")\n",
    "\n",
    "y_pred = mNB.predict(X_test)\n",
    "mNB_emp_error = (len(y_test) - (y_test == y_pred).sum()) / len(y_test)\n",
    "mNB_upper_error = mNB_emp_error + c_significance * np.sqrt(mNB_emp_error * (1 - mNB_emp_error) / len(y_test)) + c_significance / len(y_test)\n",
    "print(\"MultinomialNB upper error: \" + str(round(mNB_upper_error * 100, 2)) + \"%\")\n",
    "\n",
    "y_pred = gNB.predict(X_test)\n",
    "gNB_emp_error = (len(y_test) - (y_test == y_pred).sum()) / len(y_test)\n",
    "gNB_upper_error = gNB_emp_error + c_significance * np.sqrt(gNB_emp_error * (1 - gNB_emp_error) / len(y_test)) + c_significance / len(y_test)\n",
    "print(\"GaussianNB upper error: \" + str(round(gNB_upper_error * 100, 2)) + \"%\")\n",
    "\n",
    "y_pred = dtc.predict(X_test)\n",
    "dtc_emp_error = (len(y_test) - (y_test == y_pred).sum()) / len(y_test)\n",
    "dtc_upper_error = dtc_emp_error + c_significance * np.sqrt(dtc_emp_error * (1 - dtc_emp_error) / len(y_test)) + c_significance / len(y_test)\n",
    "print(\"DecisionTreeClassifier upper error: \" + str(round(dtc_upper_error * 100, 2)) + \"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae36b42",
   "metadata": {},
   "source": [
    "According to the calculated upper error bounds, we came to the conclusion that the BernoulliNB returns the highest accuracy with an upper error of at most 18.54% (confidence 95%)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "78a86eecd16a2785e8960468a095b76a75ad22792aa186266f234c22aafcee30"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
