{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ilyes Justin m12001643 <br>\n",
    "Seidl Stefan m11804717 <br>\n",
    "Wagermaier Daniel m01605389"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definition of input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# --- Execution mandatory --- #\n",
    "#These filename need to be defined:\n",
    "digits_train_filename = '../data/alldigits.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calc1: Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# --- Execution mandatory --- #\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "test_size = 0.3\n",
    "\n",
    "# import Data\n",
    "df = pd.read_csv(digits_train_filename)\n",
    "data = df.to_numpy()\n",
    "scalar = StandardScaler()\n",
    "\n",
    "X = data[:, :-1]\n",
    "y = data[:, -1]\n",
    "\n",
    "# Splitting (no val_set because of cross-validation in gridSearchCV)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=10)\n",
    "\n",
    "# Standardizing (mean and SDD only from train_data)\n",
    "scalar.fit(X_train)\n",
    "X_train = scalar.transform(X_train)\n",
    "X_test = scalar.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Classification - Hyperparameter Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order for us to attain the best possible accuracy for each Support Vector Machine Classifier in sklearn, we would need to implement a method where different variations of hyperparameters would all be tested on the classifiers to deliver the most accurate result. An optimal solution to this problem was by using the GridSearchCV function from sklearn. GridSearchCV does an exhaustive search over all the given parameter values for an estimator, which is then further optimized by a cross-validated grid-search. <br>\n",
    "\n",
    "Initially, we planned on using all the parameters for each of the classifiers, but shortly noticed that this was going to prove to be quite a challenge. The problem was, if all parameters were used and each parameter had a list of a minimum of 2 elements, the computational time would become exponentially longer. Especially, after further inspection, we saw that many parameters had high computational costs, like for instance break_ties in SVC(), where the documentation states that the classifier takes drastically longer to compute an estimator. Since many more parameters had similar issues we decided to only keep the essential ones in the classifiers. <br>\n",
    "\n",
    "For SVC() and NuSVC() we used the same parameters, kernel, degree, gamma and coef0, with the exception of C and nu being swapped. All of the kernels were used, asides from precomputed, because the matrix was not squared and the error \"Precomputed matrix must be a square matrix. Input is a 4200x784 matrix.\" was always returned.<br>\n",
    "\n",
    "In LinearSVC() the parameters were penalty, loss, C and intercept_scaling. The rest were deemed to be unnecessary or too computationally expensive. In LinearSVC() max_iter was ultimately set to 1000, because when it was set lower we constantly recieved \"ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\" and when it was set higher it would take too long to compute. <br>\n",
    "\n",
    "After setting the parameters for GridSearchCV, we waited until the best hyperparameters were found. After that, we created an estimator with best_estimator_ , printed the best possible parameters through best_params and finally printed the estimator's score. <br>\n",
    "\n",
    "NOTICE: We are aware that more precise results are possible, but it would be too computationally expensive and time-consuming to test out all parameters and even more values for C, nu, gamma, coef0, etc. We worked as best we could with the given timeframe to maximize our accuracies and were able to drastically narrow down what the best results were by only using a few parameters per classifier in the GridSearchCV.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RUN THIS, UNLESS YOU HAVE A LOT OF TIME! TAKES VERY LONG TO COMPUTE!\n",
    "\n",
    "parametersSVC = dict(C=(0.001,0.01,0.1,1.0,10.0), # Regularization paramter. Strength of regulaization is inversely proportiional to C. Smaller C => more generalization\n",
    "                     kernel=('linear', 'poly', 'rbf', 'sigmoid'), \n",
    "                     degree=(2,3,4), # only relevant to 'poly'\n",
    "                     gamma=('scale', 'auto', 0.1, 0.01, 0.001, 0.0001), # controls distance of influence of a training point. Low gamma => more points grouped. High gamma => less points grouped; points need to be very close to eachother\n",
    "                     coef0=(0.0,1.0,0.1,0.01,0.001,0.0001)) # relevent to 'poly' and 'sigmoid'. Independent term in kernel function \n",
    "\n",
    "SVM_SVC = GridSearchCV(SVC(), parametersSVC, n_jobs=-1, verbose=5) # n_jobs = -1 means that all processors are used\n",
    "                                                                   # verbose prints the fold, candidate parameter indexes, and starting time of each computation\n",
    "SVM_SVC.fit(X_train, y_train)\n",
    "best_SVC_estimator = SVM_SVC.best_estimator_\n",
    "\n",
    "print(SVM_SVC.best_params_)\n",
    "print(best_SVC_estimator.score(X_test, y_test))\n",
    "\n",
    "parametersLinSVC = dict(penalty=('l1','l2'), # norm used in penalization\n",
    "                        loss=('hinge','squared_hinge'), # loss function\n",
    "                        C=(0.001,0.01,0.1,1.0, 10.0), \n",
    "                        intercept_scaling=(0.1,1,5,10,15), # larger intercept_scaling => smaller effect of regularization\n",
    "                        max_iter=[1000]) # max_iter could be set higher, to get rid of warning. Typically, with 10000+ the warning did not come anymore, but takes very long to compute.\n",
    "\n",
    "SVM_LinSVC = GridSearchCV(LinearSVC(), parametersLinSVC, n_jobs=-1, verbose=5)\n",
    "SVM_LinSVC.fit(X_train, y_train)\n",
    "best_LinSVC_estimator = SVM_LinSVC.best_estimator_\n",
    "\n",
    "print(SVM_LinSVC.best_params_)\n",
    "print(best_LinSVC_estimator.score(X_test, y_test))\n",
    "\n",
    "parametersNuSVC = dict(nu=(0.01,0.05,0.1,0.5), # upper bound on the fraction of margin errors. Interval (0, 1]\n",
    "                       kernel=('linear', 'poly', 'rbf', 'sigmoid'), \n",
    "                       degree=(2,3,4),\n",
    "                       gamma=('scale','auto',10.0,1.0,0.1,0.01,0.001,0.0001),\n",
    "                       coef0=(0.0,1.0,0.1,0.01,0.001,0.0001))\n",
    "\n",
    "# this GridSearchCV would get stuck sometimes and have to be run again\n",
    "SVM_NuSVC = GridSearchCV(NuSVC(), parametersNuSVC, n_jobs=-1, verbose=5)\n",
    "SVM_NuSVC.fit(X_train, y_train)\n",
    "best_NuSVC_estimator = SVM_NuSVC.best_estimator_\n",
    "\n",
    "print(SVM_NuSVC.best_params_)\n",
    "print(best_NuSVC_estimator.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Classification: Hyperparameter Search"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, we present the code to find the best hyperparamter. GridSearchCV implemends exhaustive search over the combination of the given parameter-variables and uses 5-fold for cross-validation.<br> \n",
    "We advice to not run the following cell because of time consumption. <br>\n",
    "The following parameters for the optimization have been chosen:<br>\n",
    "- hidden_layer_sizes: To investigate how the structure affects the solution\n",
    "- alpha: To avoid over-fitting\n",
    "- learning_rate_init: To investigate how the learning rate affects the solution\n",
    "- learning_rate: To investigate how the learning rate affects the solution\n",
    "- random_state: To ensure reproducibility and try to find different optima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RUN THIS, UNLESS YOU HAVE A LOT OF TIME! TAKES VERY LONG TO COMPUTE!\n",
    "\n",
    "# Create Classifier\n",
    "max_iter = 250\n",
    "cld = MLPClassifier(max_iter=max_iter)\n",
    "\n",
    "# Choose hyperparameter to optimize (and set values)\n",
    "parameters = dict(learning_rate=[\"constant\", \"invscaling\", \"adaptive\"],\n",
    "                  hidden_layer_sizes=[(60,), (100, 60), (80, 60, 40)],\n",
    "                  alpha=np.arange(1, 2, 0.1),\n",
    "                  random_state= [4, 5, 6, 7, 42],\n",
    "                  learning_rate_init=10.0 ** -np.arange(1, 7))\n",
    "\n",
    "# Start GridSearch over Hyperparameter\n",
    "# n_jobs=-1 --> uses all cpu ressources\n",
    "# verbos=5 --> how much information of the optimization is showed\n",
    "\n",
    "clf = GridSearchCV(cld, parameters, n_jobs=-5,verbose=5)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "best_estimator = clf.best_estimator_\n",
    "# Print best hyperparameter\n",
    "print(clf.best_params_)\n",
    "print(best_estimator.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calc2: Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running GridSearchCV, we recieved our optimized hyperparameters for each of the SVM Classifiers. We then recreated each of the classifiers with the optimal parameters to return the highest testing and training accuracy attainable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Execution mandatory --- #\n",
    "\n",
    "# THIS CAN BE RUN. ONLY COMPUTES EACH CLASSFIER ONCE WITH MOST OPTIMAL HYPERPARAMETERS\n",
    "\n",
    "# Support Vector Classifier\n",
    "best_SVC = SVC(C = 10, kernel = 'poly', degree = 2, gamma = 'scale', coef0 = 0.1)\n",
    "best_SVC.fit(X_train, y_train)\n",
    "best_SVC_accuracy_test = best_SVC.score(X_test, y_test)\n",
    "best_SVC_accuracy_train = best_SVC.score(X_train, y_train)\n",
    "print('Support Vector Classifier Testing Accuracy: ' + str(round(best_SVC_accuracy_test * 100,2)) + '%')\n",
    "print('Support Vector Classifier Training Accuracy: ' + str(round(best_SVC_accuracy_train * 100,2)) + '%')\n",
    "\n",
    "# Linear Support Vector Classifier\n",
    "best_LinSVC = LinearSVC(C = 0.001, intercept_scaling = 15, loss = 'squared_hinge', max_iter = 1000, penalty = 'l2')\n",
    "best_LinSVC.fit(X_train, y_train)\n",
    "best_LinSVC_accuracy_test = best_LinSVC.score(X_test, y_test)\n",
    "best_LinSVC_accuracy_train = best_LinSVC.score(X_train, y_train)\n",
    "print('Linear Support Vector Classifier Testing Accuracy: ' + str(round(best_LinSVC_accuracy_test * 100,2)) + '%')\n",
    "print('Linear Support Vector Classifier Training Accuracy: ' + str(round(best_LinSVC_accuracy_train * 100,2)) + '%')\n",
    "\n",
    "# Nu-Support Vector Classifier\n",
    "best_NuSVC = NuSVC(nu = 0.05, kernel = 'poly', degree = 3, gamma = 0.01, coef0 = 1.0)\n",
    "best_NuSVC.fit(X_train, y_train)\n",
    "best_NuSVC_accuracy_test = best_NuSVC.score(X_test, y_test)\n",
    "best_NuSVC_accuracy_train = best_NuSVC.score(X_train, y_train)\n",
    "print('Nu-Support Vector Classifier Testing Accuracy: ' + str(round(best_NuSVC_accuracy_test * 100,2)) + '%')\n",
    "print('Nu-Support Vector Classifier Training Accuracy: ' + str(round(best_NuSVC_accuracy_train * 100,2)) + '%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing the best SVM classifier and estimation of accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To select the best SVM classifier also the upper and lower bound of the precession was calculated.\n",
    "$$ \n",
    "\\hat{\\varepsilon} − c_{\\delta/2} ∗ \\sqrt{\n",
    "    \\frac{ \\hat{\\varepsilon} ∗ (1 − \\hat{\\varepsilon})}{n}}  \n",
    "    − \\frac{c^2_{\\delta /2}}{n} \n",
    "    < \\varepsilon \\leq \n",
    "    \\hat{\\varepsilon} + c_{\\delta/2} ∗ \\sqrt{\n",
    "    \\frac{ \\hat{\\varepsilon} ∗ (1 − \\hat{\\varepsilon})}{n}}  \n",
    "    + \\frac{c^2_{\\delta /2}}{n} \n",
    "$$\n",
    " \n",
    "$\\hat{\\varepsilon}$ ...empirical error <br>\n",
    "$\\varepsilon$   ...true error <br>\n",
    "$n$ ...number of samples <br>\n",
    "$c_{\\delta/2}$  ...quantile of normaldistibution <br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from statsmodels.stats.proportion import proportion_confint\n",
    "\n",
    "significance_level = 0.05\n",
    "delta_half = 1 - significance_level / 2 # since confidence interval is symmetric, we can use 1 - alpha / 2\n",
    "c_delta_half = stats.norm.ppf(delta_half)\n",
    "\n",
    "# calculate the confidence interval for the difference of the accuracies\n",
    "best_SVC_upper_test_accuracy = best_SVC_accuracy_test + c_delta_half * np.sqrt((best_SVC_accuracy_test * (1 - best_SVC_accuracy_test)) / len(y_test)) + c_delta_half ** 2 / len(y_test)\n",
    "best_SVC_lower_test_accuracy = best_SVC_accuracy_test - c_delta_half * np.sqrt((best_SVC_accuracy_test * (1 - best_SVC_accuracy_test)) / len(y_test)) - c_delta_half ** 2 / len(y_test)\n",
    "print(f'''\n",
    "    SVC classifier:\n",
    "    upper accuracy bound: {round(best_SVC_upper_test_accuracy * 100, 2)} \n",
    "    mean accuracy: {round(best_SVC_accuracy_test * 100, 2)}\n",
    "    lower accuracy bound: {round(best_SVC_lower_test_accuracy * 100, 2)}''')\n",
    "\n",
    "# calculate the confidence interval for the difference of the accuracies\n",
    "best_LinSVC_upper_test_accuracy = best_LinSVC_accuracy_test + c_delta_half * np.sqrt((best_LinSVC_accuracy_test * (1 - best_LinSVC_accuracy_test)) / len(y_test)) + c_delta_half ** 2 / len(y_test)\n",
    "best_LinSVC_lower_test_accuracy = best_LinSVC_accuracy_test - c_delta_half * np.sqrt((best_LinSVC_accuracy_test * (1 - best_LinSVC_accuracy_test)) / len(y_test)) - c_delta_half ** 2 / len(y_test)\n",
    "print(f'''\n",
    "    Linear SVC classifier:\n",
    "    upper accuracy bound: {round(best_LinSVC_upper_test_accuracy * 100, 2)}\n",
    "    mean accuracy: {round(best_LinSVC_accuracy_test * 100, 2)}\n",
    "    lower accuracy bound: {round(best_LinSVC_lower_test_accuracy * 100, 2)}''')\n",
    "\n",
    "# calculate the confidence interval for the difference of the accuracies\n",
    "best_NuSVC_upper_test_accuracy = best_NuSVC_accuracy_test + c_delta_half * np.sqrt((best_NuSVC_accuracy_test * (1 - best_NuSVC_accuracy_test)) / len(y_test)) + c_delta_half ** 2 / len(y_test)\n",
    "best_NuSVC_lower_test_accuracy = best_NuSVC_accuracy_test - c_delta_half * np.sqrt((best_NuSVC_accuracy_test * (1 - best_NuSVC_accuracy_test)) / len(y_test)) - c_delta_half ** 2 / len(y_test)\n",
    "print(f'''\n",
    "    Nu-SVC classifier:\n",
    "    upper accuracy bound: {round(best_NuSVC_upper_test_accuracy * 100, 2)}\n",
    "    mean accuracy: {round(best_NuSVC_accuracy_test * 100, 2)}\n",
    "    lower accuracy bound: {round(best_NuSVC_lower_test_accuracy * 100, 2)}''')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question on different results for the confidence interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question to professor Auer:\n",
    "# Why do I get different results when I use the statsmodels.stats.proportion.proportion_confint function?\n",
    "\n",
    "lower_bound, upper_bound = proportion_confint(best_SVC_accuracy_test * len(y_test), len(y_test), alpha = 0.05, method = 'normal')\n",
    "print(f'''proportion_confint: {round(lower_bound * 100, 4)} - {round(upper_bound * 100, 4)} \n",
    "according to formula: {round(best_SVC_lower_test_accuracy * 100, 4)} - {round(best_SVC_upper_test_accuracy * 100, 4)}''')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "bound_extension = 0.01\n",
    "lower_bound = min(best_SVC_lower_test_accuracy, best_LinSVC_lower_test_accuracy, best_NuSVC_lower_test_accuracy) - bound_extension\n",
    "upper_bound = max(best_SVC_upper_test_accuracy, best_LinSVC_upper_test_accuracy, best_NuSVC_upper_test_accuracy) + bound_extension\n",
    "data_points = np.arange(lower_bound, upper_bound, 0.001)\n",
    "\n",
    "plt.plot(data_points, stats.norm.pdf(data_points, best_SVC_accuracy_test, np.sqrt((best_SVC_accuracy_test * (1 - best_SVC_accuracy_test)) / len(y_test))), label = 'SVC')\n",
    "plt.plot(data_points, stats.norm.pdf(data_points, best_LinSVC_accuracy_test, np.sqrt((best_LinSVC_accuracy_test * (1 - best_LinSVC_accuracy_test)) / len(y_test))), label = 'Linear SVC')\n",
    "plt.plot(data_points, stats.norm.pdf(data_points, best_NuSVC_accuracy_test, np.sqrt((best_NuSVC_accuracy_test * (1 - best_NuSVC_accuracy_test)) / len(y_test))), label = 'Nu-SVC')\n",
    "plt.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final statement on SVM classifier selection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the confidence interval of the linear SVC does not intersect with the confidence interval of the other classifiers and has a lower accuracy, we can conclude that the linear SVC is not the best SVM classifier for this dataset. In case of the SVC and NuSVC the confidence interval of both intersect. As the mean of the NuSVC is higher it is more likely that this classifier will perform best. Hence the NuSVC classifier was chosen as the best classifier found. Nevertheless, I would be necessary to investigate the intersected area of both bell curves (SVC and NuSVC) and perform a statistical test on how confident we could be that the found NuSVC is better than the SVC!<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "source": [
    "# Calc3: Neural Network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create our Classifier we used the MLPClassifier of Sklearn and for Hyperparameter-Optimization we used GridSearchCV.<br>\n",
    "We calculated the best hyperparameter separately because of time consumption and used the found parameter to create and train the final Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Execution mandatory --- #\n",
    "\n",
    "# Set best hyperparameter\n",
    "activation = \"relu\"\n",
    "solver = \"adam\"\n",
    "learning_rate = \"adaptive\"\n",
    "hidden_layer_sizes = (100, 60)\n",
    "alpha = 1.5\n",
    "random_state = 4\n",
    "learning_rate_init = 0.001\n",
    "\n",
    "# Create Classifier\n",
    "finalNN = MLPClassifier(max_iter=250, activation=activation, solver=solver, learning_rate=learning_rate,\n",
    "                    hidden_layer_sizes=hidden_layer_sizes, random_state=random_state, alpha=alpha,\n",
    "                    learning_rate_init=learning_rate_init)\n",
    "\n",
    "# Train classifier\n",
    "finalNN.fit(X_train, y_train)\n",
    "print(\"Accuracy on Training-Data: \" + str(finalNN.score(X_train, y_train)*100) + \"%\")\n",
    "print(\"Accuracy on Test-Data: \" + str(finalNN.score(X_test, y_test)*100) + \"%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimation of MLPC accuracy "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The upper and lower bound of the precession was calculated with the following formula (same as for SVM):\n",
    "$$ \n",
    "\\hat{\\varepsilon} − c_{\\delta/2} ∗ \\sqrt{\n",
    "    \\frac{ \\hat{\\varepsilon} ∗ (1 − \\hat{\\varepsilon})}{n}}  \n",
    "    − \\frac{c^2_{\\delta /2}}{n} \n",
    "    < \\varepsilon \\leq \n",
    "    \\hat{\\varepsilon} + c_{\\delta/2} ∗ \\sqrt{\n",
    "    \\frac{ \\hat{\\varepsilon} ∗ (1 − \\hat{\\varepsilon})}{n}}  \n",
    "    + \\frac{c^2_{\\delta /2}}{n} \n",
    "$$\n",
    " \n",
    "$\\hat{\\varepsilon}$ ...empirical error <br>\n",
    "$\\varepsilon$   ...true error <br>\n",
    "$n$ ...number of samples <br>\n",
    "$c_{\\delta/2}$  ...quantile of normaldistibution <br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLPC_upper_bound = finalNN.score(X_test, y_test) + c_delta_half * np.sqrt((finalNN.score(X_test, y_test) * (1 - finalNN.score(X_test, y_test))) / len(y_test)) + c_delta_half ** 2 / len(y_test)\n",
    "MLPC_lowe_bound = finalNN.score(X_test, y_test) - c_delta_half * np.sqrt((finalNN.score(X_test, y_test) * (1 - finalNN.score(X_test, y_test))) / len(y_test)) - c_delta_half ** 2 / len(y_test)\n",
    "print(f'''\n",
    "    Multi-Layer Perceptron classifier:\n",
    "    upper accuracy bound: {round(MLPC_upper_bound * 100, 2)}\n",
    "    mean accuracy: {round(finalNN.score(X_test, y_test) * 100, 2)}\n",
    "    lower accuracy bound: {round(MLPC_lowe_bound * 100, 2)}''')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "interval_extension = 0.01\n",
    "lower_bound = MLPC_lowe_bound - interval_extension\n",
    "upper_bound = MLPC_upper_bound + interval_extension\n",
    "\n",
    "data_points = np.arange(lower_bound, upper_bound, 0.001)\n",
    "plt.plot(data_points, stats.norm.pdf(data_points, finalNN.score(X_test, y_test), np.sqrt((finalNN.score(X_test, y_test) * (1 - finalNN.score(X_test, y_test))) / len(y_test))), label = 'MLPC')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison SVC and MLPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To execute this cell, you need to execute every cell of Calc1, Calc2 and Calc3 first! \n",
    "interval_extension = 0.01\n",
    "lower_bound = min(best_SVC_lower_test_accuracy, best_LinSVC_lower_test_accuracy, best_NuSVC_lower_test_accuracy, MLPC_lowe_bound) - interval_extension\n",
    "upper_bound = max(best_SVC_upper_test_accuracy, best_LinSVC_upper_test_accuracy, best_NuSVC_upper_test_accuracy, MLPC_upper_bound) + interval_extension\n",
    "\n",
    "data_points = np.arange(lower_bound, upper_bound, 0.001)\n",
    "plt.plot(data_points, stats.norm.pdf(data_points, best_SVC_accuracy_test, np.sqrt((best_SVC_accuracy_test * (1 - best_SVC_accuracy_test)) / len(y_test))), label = 'SVC')\n",
    "plt.plot(data_points, stats.norm.pdf(data_points, best_LinSVC_accuracy_test, np.sqrt((best_LinSVC_accuracy_test * (1 - best_LinSVC_accuracy_test)) / len(y_test))), label = 'Linear SVC')\n",
    "plt.plot(data_points, stats.norm.pdf(data_points, best_NuSVC_accuracy_test, np.sqrt((best_NuSVC_accuracy_test * (1 - best_NuSVC_accuracy_test)) / len(y_test))), label = 'Nu-SVC')\n",
    "plt.plot(data_points, stats.norm.pdf(data_points, finalNN.score(X_test, y_test), np.sqrt((finalNN.score(X_test, y_test) * (1 - finalNN.score(X_test, y_test))) / len(y_test))), label = 'MLPC')\n",
    "plt.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the graph above we can conclude that the linear SVC will perform worst since the confidence intervals don't intersect with any other classifier. Regarding the other classifiers it is difficult to choose which one is the most accurate classifier as intersected areas is quite large. Therefore, it would be necessary to perform a statistical test to determine which classifier is the best one. However, we can state that the calculated accuracy of our classifiers is 95% confident."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#These classifiers need to be defined:\n",
    "digits_SVM = best_NuSVC\n",
    "digits_nn = finalNN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".MachineLearningAlgorithmsVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "2af3fa6deb4540203573c2f77ac0c6625a140871d003bbf07916785469cd40d1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
